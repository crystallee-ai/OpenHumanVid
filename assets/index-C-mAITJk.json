[
    {
        "template": "title",
        "props": {
            "title": "OpenHumanVid",
            "subtitle": "A Large-Scale High-Quality Dataset for Enhancing Human-Centric Video Generation",
            "authors": [
                [
                    {
                        "name": "Hui Li",
                        "homepage": "https://github.com/crystallee-ai",
                        "suffix": "1*"
                    },
                    {
                        "name": "Mingwang Xu",
                        "homepage": "https://github.com/xumingw",
                        "suffix": "1*"
                    },
                    {
                        "name": "Yun Zhan",
                        "homepage": "https://github.com/subazinga",
                        "suffix": "1"
                    },
                    {
                        "name": "Shan Mu",
                        "homepage": "https://github.com/AricGamma",
                        "suffix": "1"
                    },
                    {
                        "name": "Jiaye Li",
                        "homepage": "https://github.com/Studentxll",
                        "suffix": "1"
                    },
                    {
                        "name": "Kaihui Cheng",
                        "homepage": "https://github.com/Kaihui-Cheng",
                        "suffix": "1"
                    },
                    {
                        "name": "Yuxuan Chen",
                        "homepage": "https://github.com/Shr1ke777",
                        "suffix": "1"
                    },
                    {
                        "name": "Tan Chen",
                        "homepage": "https://github.com/tchen0623",
                        "suffix": "1"
                    }
                ],
                [
                    {
                        "name": "Mao Ye",
                        "homepage": "",
                        "suffix": "3"
                    },
                    {
                        "name": "Jingdong Wang",
                        "homepage": "https://jingdongwang2017.github.io/",
                        "suffix": "2"
                    },
                    {
                        "name": "Siyu Zhu",
                        "homepage": "https://sites.google.com/site/zhusiyucs/home",
                        "suffix": "1✉️"
                    }
                ],
                [
                    {
                        "name": "Fudan University",
                        "homepage": "",
                        "prefix": "1"
                    },
                    {
                        "name": "Baidu Inc.",
                        "homepage": "",
                        "prefix": "2"
                    },
                    {
                        "name": "Shanghai Jiaotong University",
                        "homepage": "",
                        "prefix": "3"
                    }
                ]
            ],
            "resources": {
                "pdf": "https://arxiv.org/pdf/2410.00115",
                "arxiv": "https://arxiv.org/abs/2412.00115",
                "github": "https://github.com/fudan-generative-vision/OpenHumanVid"
            },
            "mainVideo": "https://cdn.aondata.work/OpenHumanVid/assets/videos/main.mp4"
        }
    },
    {
        "template": "video-carousel",
        "props": {
            "id": "showcase",
            "title": "More Detail(Coming soon)",
            "items": [],
            "count": 1
        }
    },
    {
        "template": "abstract",
        "props": {
            "figure": "//cdn.aondata.work/OpenHumanVid/assets/images/teaser.jpg",
            "content": "Recent advancements in visual generation technologies have markedly increased the scale and availability of video datasets, which are crucial for training effective video generation models. However, a significant lack of high quality, human-centric video datasets presents a challenge to progress in this field. To bridge this gap, we introduce OpenHumanVid, a large-scale and high-quality human-centric video dataset characterized by precise and detailed captions that encompass both human appearance and motion states, along with supplementary human motion conditions, including skeleton sequences and speech audio. To validate the efficacy of this dataset and the associated training strategies, we propose an extension of existing classical diffusion transformer architectures and conduct further pretraining of our models on the proposed dataset. Our findings yield two critical insights: First, the incorporation of a large-scale, high-quality dataset substantially enhances evaluation metrics for generated human videos while preserving performance in general video generation tasks. Second, the effective alignment of text with human appearance, human motion, and facial motion is essential for producing high-quality video outputs. Based on these insights and corresponding methodologies, the straightforward extended network trained on the proposed dataset demonstrates an obvious improvement in the generation of human-centric videos."
        }
    },
    {
        "template": "bibtex",
        "props": {
            "bibTeX": "@misc{li2024OpenHumanVid,\n\ttitle={OpenHumanVid: A Large-Scale High-Quality Dataset for Enhancing Human-Centric Video Generation}, \n\tauthor={Hui Li and Mingwang Xu and Yun Zhan and Shan Mu and Jiaye Li and Kaihui Cheng and Yuxuan Chen and Tan Chen and Mao Ye and Jingdong Wang and Siyu Zhu},\n\tyear={2024},\n\teprint={2410.00115},\n\tarchivePrefix={arXiv},\n\tprimaryClass={cs.CV}\n}"
        }
    }
]